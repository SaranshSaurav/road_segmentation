{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b12148-59e0-4bb9-9d1c-9d7b6e0bd415",
   "metadata": {},
   "source": [
    "### Road segmentation with CNN\n",
    "\n",
    "- uses a CNN based segmentation network with 2 skipp connections, similar to FCN16\n",
    "- the input is an RGB image, the output the segmentation mask with the same dimensions as the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f0121e-b7b7-4bdb-b2de-6e02b5a7d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "from PIL import Image,ImageFilter\n",
    "from utils import config\n",
    "from utils import utils\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "USE_GPU=config.USE_GPU\n",
    "\n",
    "if USE_GPU==1:\n",
    "    def get_available_gpus():\n",
    "        local_device_protos = device_lib.list_local_devices()\n",
    "        return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    print (get_available_gpus())\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c110dfbf-0998-4fe0-8d8d-9515f77dc402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\**\\*info.rec Meta file number:  0\n"
     ]
    }
   ],
   "source": [
    "IMG_W = config.IMG_W\n",
    "IMG_H = config.IMG_H\n",
    "IMG_CHANNELS = config.IMG_CHANNELS\n",
    "NET_SHAPE = config.NET_SHAPE\n",
    "\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SPLIT = 0.70\n",
    "data_location = config.DATA_LOCATION\n",
    "\n",
    "file = config.FILE\n",
    "\n",
    "files = glob.glob(data_location + file, recursive=True)\n",
    "print (data_location + file, \"Meta file number: \", len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e2e7-3e77-4c78-9982-c67fa72e90cc",
   "metadata": {},
   "source": [
    "### Data loader \n",
    "to load automatically a defined batch amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48a7709-0232-443a-83fe-c4e3d6043152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sample_nr: 0  Train: 0  Val: 0 Test: 0\n"
     ]
    }
   ],
   "source": [
    "class DataLoader(keras.utils.Sequence):\n",
    "    def __init__(self, data, batch_size, use_random=True,input_shape=[200,150,3], net_shape=[200,150], file_tags=['']):\n",
    "        self.batch_size = batch_size\n",
    "        self.use_random = use_random\n",
    "        self.data = data\n",
    "        if self.use_random == True:\n",
    "            np.random.shuffle(self.data)\n",
    "        self.input_shape = input_shape\n",
    "        self.net_shape=net_shape\n",
    "        \n",
    "    # get data lenght\n",
    "    def __len__(self):\n",
    "        return len(self.data)//self.batch_size\n",
    "    \n",
    "    # get item form batch\n",
    "    def __getitem__(self, indx):\n",
    "        batch_data = self.data[indx*self.batch_size:(indx+1)*self.batch_size]\n",
    "        #print (batch_data)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        for it in batch_data:\n",
    "            v_data = cv2.imread(it['rgb_c'])\n",
    "            v_data = cv2.resize(v_data,dsize=(self.input_shape[0],self.input_shape[1]))\n",
    "                        \n",
    "            if self.input_shape[2] == 1:\n",
    "                v_data = cv2.cvtColor(v_data, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            v_data = utils.fast_normalization(v_data)\n",
    "            \n",
    "            \n",
    "            # create label\n",
    "            v_label = cv2.imread(it['depth_c'])\n",
    "            v_label = cv2.resize(v_label,dsize=(self.net_shape[0],self.net_shape[1]))\n",
    "            v_label = utils.fast_normalization(v_label)\n",
    "            \n",
    "            X.append(v_data)\n",
    "            y.append(v_label)\n",
    "                        \n",
    "            \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        return X,y\n",
    "            \n",
    "    \n",
    "    # do something on epoch end\n",
    "    def on_epoch_end(self):\n",
    "        if self.use_random == True:\n",
    "            np.random.shuffle(self.data)\n",
    "            \n",
    "data = []\n",
    "\n",
    "fn_filter = [lambda x: True]\n",
    "\n",
    "for file in files:\n",
    "    print (\"Loading:\",file)\n",
    "    data.extend(utils.load_data(file,filter_fn=fn_filter, file_tag=['rgb_c','depth_c']))\n",
    "\n",
    "data = np.array(data)\n",
    "print (len(data))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# split the data\n",
    "train, val, test = np.split(data,[int(len(data)*SPLIT), int(len(data)*0.9)])\n",
    "print (\"Sample_nr:\",len(data), \" Train:\", len(train), \" Val:\",len(val), \"Test:\", len(test))\n",
    "\n",
    "obj_data_train= DataLoader(train, batch_size=BATCH_SIZE, input_shape=[NET_SHAPE[0],NET_SHAPE[1],IMG_CHANNELS], net_shape=NET_SHAPE)\n",
    "obj_data_val= DataLoader(val, batch_size=BATCH_SIZE, input_shape=[NET_SHAPE[0],NET_SHAPE[1],IMG_CHANNELS], net_shape=NET_SHAPE)\n",
    "\n",
    "obj_data_test= DataLoader(test, batch_size=BATCH_SIZE, input_shape=[NET_SHAPE[0],NET_SHAPE[1],IMG_CHANNELS], net_shape=NET_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6aad9a-b027-4068-b0f9-98052858c49b",
   "metadata": {},
   "source": [
    "### Visualize data\n",
    "Take the input image and overlay over it the segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876f5f8b-f2d6-42d7-aff3-2586c63c9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of columns must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saura\\Downloads\\road_segmentation-main\\segmentation_trainer.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/saura/Downloads/road_segmentation-main/segmentation_trainer.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_sample\u001b[39m=\u001b[39mobj_data_train\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/saura/Downloads/road_segmentation-main/segmentation_trainer.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m (test_sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape, test_sample[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/saura/Downloads/road_segmentation-main/segmentation_trainer.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49msubplots(nrows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,ncols\u001b[39m=\u001b[39;49mtest_sample[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/saura/Downloads/road_segmentation-main/segmentation_trainer.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fig\u001b[39m.\u001b[39mset_size_inches(\u001b[39m30\u001b[39m,\u001b[39m60\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/saura/Downloads/road_segmentation-main/segmentation_trainer.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39mlen\u001b[39m(test_sample[\u001b[39m0\u001b[39m])\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:1502\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \u001b[39mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \n\u001b[0;32m   1500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m fig \u001b[39m=\u001b[39m figure(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1502\u001b[0m axs \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msubplots(nrows\u001b[39m=\u001b[39;49mnrows, ncols\u001b[39m=\u001b[39;49mncols, sharex\u001b[39m=\u001b[39;49msharex, sharey\u001b[39m=\u001b[39;49msharey,\n\u001b[0;32m   1503\u001b[0m                    squeeze\u001b[39m=\u001b[39;49msqueeze, subplot_kw\u001b[39m=\u001b[39;49msubplot_kw,\n\u001b[0;32m   1504\u001b[0m                    gridspec_kw\u001b[39m=\u001b[39;49mgridspec_kw, height_ratios\u001b[39m=\u001b[39;49mheight_ratios,\n\u001b[0;32m   1505\u001b[0m                    width_ratios\u001b[39m=\u001b[39;49mwidth_ratios)\n\u001b[0;32m   1506\u001b[0m \u001b[39mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32mc:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:905\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwidth_ratios\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must not be defined both as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mparameter and as key in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mgridspec_kw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    903\u001b[0m     gridspec_kw[\u001b[39m'\u001b[39m\u001b[39mwidth_ratios\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m width_ratios\n\u001b[1;32m--> 905\u001b[0m gs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_gridspec(nrows, ncols, figure\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgridspec_kw)\n\u001b[0;32m    906\u001b[0m axs \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39msubplots(sharex\u001b[39m=\u001b[39msharex, sharey\u001b[39m=\u001b[39msharey, squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m    907\u001b[0m                   subplot_kw\u001b[39m=\u001b[39msubplot_kw)\n\u001b[0;32m    908\u001b[0m \u001b[39mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32mc:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:1527\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[39mReturn a `.GridSpec` that has this figure as a parent.  This allows\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[39mcomplex layout of Axes in the figure.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \n\u001b[0;32m   1524\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m _ \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfigure\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m gs \u001b[39m=\u001b[39m GridSpec(nrows\u001b[39m=\u001b[39;49mnrows, ncols\u001b[39m=\u001b[39;49mncols, figure\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1528\u001b[0m \u001b[39mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32mc:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\gridspec.py:379\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhspace \u001b[39m=\u001b[39m hspace\n\u001b[0;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure \u001b[39m=\u001b[39m figure\n\u001b[1;32m--> 379\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(nrows, ncols,\n\u001b[0;32m    380\u001b[0m                  width_ratios\u001b[39m=\u001b[39;49mwidth_ratios,\n\u001b[0;32m    381\u001b[0m                  height_ratios\u001b[39m=\u001b[39;49mheight_ratios)\n",
      "File \u001b[1;32mc:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\gridspec.py:52\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     50\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of rows must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mnrows\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(ncols, Integral) \u001b[39mor\u001b[39;00m ncols \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of columns must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mncols\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nrows, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ncols \u001b[39m=\u001b[39m nrows, ncols\n\u001b[0;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_height_ratios(height_ratios)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of columns must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sample=obj_data_train.__getitem__(0)\n",
    "print (test_sample[0].shape, test_sample[1].shape)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1,ncols=test_sample[0].shape[0]//2)\n",
    "fig.set_size_inches(30,60)\n",
    "for i in range (len(test_sample[0])//2):\n",
    "    sin = test_sample[0][i]*255\n",
    "    sout = test_sample[1][i]*255\n",
    "    sin = cv2.cvtColor(sin.astype(np.uint8),cv2.COLOR_BGR2RGB)\n",
    "    sout = sout.astype(np.uint8)\n",
    "    \n",
    "    img = cv2.addWeighted(sin, 1, sout,0.5, 1)\n",
    "    axs[i].imshow(img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9c8ae-0723-4a35-acca-df5d8d73f116",
   "metadata": {},
   "source": [
    "### Create the segmentation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe008107-1f71-413b-b445-0d966c3b9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_model(img_size=[200,160], img_channels=3, batch_size=8, name=\"seg_net2\"):\n",
    "    \n",
    "    data_in = keras.Input(shape=(img_size[1],img_size[0],img_channels))\n",
    "\n",
    "    val_c1 = keras.layers.Conv2D(128,(5,5), strides=(2,2), activation=\"relu\", padding=\"SAME\", name=\"conv1\")(data_in)\n",
    "    val = keras.layers.Dropout(0.2)(val_c1)\n",
    "    \n",
    "    val_c2 = keras.layers.Conv2D(64,(4,4), strides=(1,1), activation=\"relu\", padding=\"SAME\", name=\"conv2\")(val)\n",
    "    val = keras.layers.Dropout(0.2)(val_c2)\n",
    "    \n",
    "    val = keras.layers.Conv2D(32,(4,4), strides=(2,2), activation=\"relu\", padding=\"SAME\", name=\"conv3\")(val)\n",
    "    val = keras.layers.Dropout(0.2)(val)\n",
    "\n",
    "\n",
    "    val = keras.layers.Conv2DTranspose(32,(2,2),strides=(2,2), activation=\"relu\", padding=\"SAME\", name=\"tconv3\")(val)\n",
    "    \n",
    "    val = keras.layers.Conv2DTranspose(64,(2,2),strides=(1,1), activation=\"relu\", padding=\"SAME\", name=\"tconv2\")(val)\n",
    "    val = keras.layers.Add()([val, val_c2])\n",
    "    \n",
    "    val = keras.layers.Conv2DTranspose(128,(4,4),strides=(1,1), activation=\"relu\", padding=\"SAME\", name=\"tconv1\")(val)\n",
    "    val = keras.layers.Add()([val, val_c1])\n",
    "    \n",
    "    val = keras.layers.Conv2DTranspose(3,(2,2),strides=(2,2), padding=\"SAME\")(val)\n",
    "\n",
    "    out = keras.layers.Activation(\"sigmoid\")(val)\n",
    "    \n",
    "    model = keras.Model(inputs=data_in,outputs=out, name=name)\n",
    "    model.summary()\n",
    "    keras.utils.plot_model(model,to_file=\".\\\\info\\\\\"+name+\".png\",show_shapes=True)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),loss=[keras.losses.mae], metrics=['mae'])\n",
    "    print (data_in.shape, out.shape)\n",
    "\n",
    "    img = plt.imread(\".\\\\info\\\\\"+ name + '.png')\n",
    "    plt.figure(figsize=(10,12))\n",
    "    plt.imshow(img)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = seg_model(img_size=[NET_SHAPE[0],NET_SHAPE[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331dcd7-54d5-49f0-bbfe-436115b1f5ff",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cdc66-639b-46b5-805f-b6756d17647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model train\n",
    "epochs = 30\n",
    "steps = 100\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='seg.h5', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "hist = model.fit(x=obj_data_train,validation_data=obj_data_val, epochs=epochs, callbacks=[checkpoint,early_stop])\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34f34d-cbc4-41a6-9d19-7fef4bce6a14",
   "metadata": {},
   "source": [
    "### Compute model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a32bec-4afd-43d8-951a-0feda70977fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "model = keras.models.load_model(config.MODEL_FILE)\n",
    "res_eval = model.evaluate(x=obj_data_test)\n",
    "print (res_eval)\n",
    "\n",
    "jscore = []\n",
    "for b in range (len(obj_data_test)):\n",
    "    test_sample=obj_data_test.__getitem__(0)\n",
    "    for i in range (len(test_sample[0])):\n",
    "        sin = test_sample[0][i]\n",
    "        sout_true = test_sample[1][i]\n",
    "        \n",
    "        imgs = cv2.resize(sin.copy(), dsize=config.NET_SHAPE)\n",
    "        nimg = np.array([imgs])\n",
    "        mret = model.predict(nimg,batch_size=1)\n",
    "        \n",
    "        sin = np.array(sin*255).astype(np.uint8)\n",
    "        sout = np.array(mret[0]*255).astype(np.uint8)\n",
    "        sout_true = np.array(sout_true*255).astype(np.uint8)\n",
    "    \n",
    "        js = jaccard_score(y_true=sout_true.flatten(),y_pred=sout.flatten(), average=\"micro\")\n",
    "        \n",
    "        jscore.append(js)\n",
    "\n",
    "print ('Average IOU: {:.2f}'.format(np.average(np.array(jscore))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2472a73-95bc-4280-b9bb-07c871747b05",
   "metadata": {},
   "source": [
    "### Test detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea61a9-8956-4770-a1b6-1e8fb48fe51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "test_sample=obj_data_test.__getitem__(0)\n",
    "print (test_sample[0].shape, test_sample[1].shape)\n",
    "\n",
    "for i in range (len(test_sample[0])):\n",
    "    sin = test_sample[0][i]\n",
    "    sout_true = test_sample[1][i]\n",
    "    \n",
    "    imgs = cv2.resize(sin.copy(), dsize=config.NET_SHAPE)\n",
    "\n",
    "    nimg = np.array([imgs])\n",
    "    mret = model.predict(nimg,batch_size=1)\n",
    "\n",
    "    #sout = cv2.cvtColor(sin.astype(np.uint8),cv2.COLOR_BGR2RGB)\n",
    "    sin = np.array(sin*255).astype(np.uint8)\n",
    "    sout = np.array(mret[0]*255).astype(np.uint8)\n",
    "\n",
    "    sout_true = np.array(sout_true*255).astype(np.uint8)\n",
    "    jscore = jaccard_score(y_true=sout_true.flatten(),y_pred=sout.flatten(), average=\"micro\")\n",
    "    \n",
    "    img_over = cv2.addWeighted(sin,1,sout,0.5, 1)\n",
    "    img = cv2.hconcat([sin,sout, img_over, sout_true])\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.xlabel(\"1.Input Image/ 2.Predicted / 3.Input+segmented, 4.Ground truth, IOU:{:.2f}\".format(jscore))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e0ac8-6dd1-43de-a184-128c9d627fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
